When the oil price falls, the sector traditionally turned its attention to improving its operational efficiency and managing risk. However, when prices began to rise the focus moves back to how best to invest in capital projects. Over several cycles that attitude has meant that there has never been a focused effort on addressing the underlying inefficiencies in the way that the upstream sector does business. However, the lower for longer cycle that the industry is enduring this time around, along with the other challenges it is facing may be changing that. “I think in certain cases, like the North Sea where it is an expensive basin, you have got to start asking how you can be more efficient,” Phil Murray, CEO of Petrotechnics says. “I think as future demand for oil doesn't inexorably rise oil has got to be digital to remain competitive as a source of energy. What's interesting is why it has been so difficult in digitizing oil and gas? They're not invested a lot in terms of IT.” Getting value from digitization Oil and gas has not achieved the radical improvements that other industries have experienced from digitalization. There are many reasons for that but primarily because it is a messy business in more ways than one. The data is very messy, a lot of it is in silos and is legacy data. “To me, it is a journey, and people like to talk about the sexy end-journey which is your automated decisions, digital twins that remove the human input,” Murray adds. “To get to automated decisions, part of that journey is about helping the human input; helping humans make better decisions. Until you can get your humans making better decisions, you cannot just plug AI into messy data.” A slow journey The message that comes from oil and gas companies on the road to digitization is that there are five reasons for the slow take-up: silos, dirty data, the long life of assets, lack of standardization and people. “I think what is interesting is that things like AI is not the answer when you have all of those challenges,” Murray explains. “You have got to solve those challenges to be able to be fully digital, and it is a journey. Even with your silo, messy data, legacy facilities, you can still try to get on the journey. One of the things that we talk about is creating a common currency from your messy data. Looking at how you can combine that data to give you a shared view of operational reality.” Managing risk In terms of risk, this can occur in operations from many areas whether it is a piece of equipment that is not working, a backlog of safety-critical maintenance, or particularly risky activity. It is a combination of those risks that will lead to potential incidents. “What is very difficult is how to create that single shared view of that reality and give real-time visibility of your asset risk?” Murray continues. “The approach we have taken is, rather than recognizing all of those problems, how can you create common currencies that allow us to aggregate and clean the data in a way that can give you a more credible picture? It has got to give you a picture of how your asset is operating.” Struggling with standardization Without standardization, data can mean a different thing from different sources and give a picture that does not reflect reality. Each facility is designed and engineered differently and to get a common currency many operators talk of making everything Vanilla, where everything is reported in the same way, and everything means the same thing. “If that were my digital journey I would not start from this position,” Murray explains. “If you try and make all your data Vanilla, you end up adding shades of Vanilla. What we do is ask how we can get a combination of flavors of data that will still give us some meaningful insight? Data overload An oft-heard comment is that there is too much data in the oil and gas sector to manage, but there is an interesting contradiction there. If you to Data Scientists, they will say that it is not a lot of data that is the problem but the amount of messy data. It is about looking at the data sets and looking at where the meaningful data is and how you can collate that in a way that can provide insight. “If you are looking to move to smart operations or smart facilities, if you break down the problem it is about getting your data systems closer to your reality,” Murray says. “What we need is a shared view of reality and to integrate our systems better. We need to what I call humanly enable data. You have got to have data presented in a way that human beings can act on it and interact with.” A balancing act Within many digital programmes there is a triumvirate of ambitions; to reduce risk, cut costs and improve productivity. However, do these apparently disparate ambitions naturally go hand-in-hand on a digitalization program? “They do for us as a company because we see them inextricably linked,” Murray concludes. “I think the problem with some digitalization initiatives is that you might digitalize one part of it. For us, the operational excellence is being able to operate efficiently, operate safely and reduce your risks and reduce costs. “You need to help your people make decisions that are more efficient, reduce risk and are less expensive. You need to address all those three areas to help people make decisions. If you have a cost initiative, that only pulls one lever. If you have a risk management initiative, it only pulls one lever, but real business decisions mean you have got to balance all three.” 