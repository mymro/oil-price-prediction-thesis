We are worried. Some of the things we worry about are the same as everyone else who is trying to imagine the impact of emerging technologies on our lives. We worry about how smartphones are consuming our attention and mediate our relationships. We worry about how much of our decision-making we ought delegate to machines. We worry about protecting privacy. We worry about how to prevent people being exploited by industries and their technological developments. We are concerned for all the people who will lose jobs as a result of automation. And like them, we worry about the right directions we need to take going forward. We call this field of worry “ethics.” What is useful about thinking of this field of worry in ethical terms is that it moves us from being passive recipients of problems to active participants determining our course. It is from this active and engaged perspective that we invite readers to join us in thinking towards our future. We are told that we stand at the brink of a new Industrial Revolution. This time around, it is data that needs refinement through artificial intelligence techniques as opposed to crude oil. We worry that this analogy might be fitting on more levels than one. Two centuries ago, arsonists attacked the Albion Flour Mills on the banks of the Thames in London. The devastation was celebrated by independent millers. We know them today as the “dark Satanic Mills” made famous in William Blake’s poetry. It was not just Mills in London that burned. As the Industrial Revolution raged, communities were displaced, aristocracies overthrown, and genocides were committed. Voices concerned about the sustainability of it all were muted. Short-term ambitions outweighed long-term consequence. At no point was there a moratorium calling for a halt to industrial society while the long term effects on our environment were considered. Today, we eat food cultivated with chemicals and breathe air infused with the reek of industry. We enter this coming decade with no foresight as to how long the Anthropocene will endure. This new Industrial Revolution is not short of its detractors. Ted Kaczynski became infamous for his calls not just to halt industrial society but to abandon it–a neo-Amish turned terrorist—such was his hatred of proponents of industry and his inability to reconcile individual freedom with a system of technology. While we hope the Unabomber remains an outlier, the “techlash” is gaining momentum and trust in Big Tech has fallen recently to new lows. There are some who argue that social media was responsible for distorting our democratic processes leading to the election of Donald Trump and the Brexit referendum result. Whether you subscribe to this position or not, it is clear that our relationship with sources of “authority” in the sense of providence of information has fundamentally shifted. While the technology industry indulge themselves as to how best to handle “deepfakes,” journalists and newspapers continue to face an existential threat. Those battling to survive also include high street retailers. While Mark Zuckerberg’s organization has been largely responsible for decimating newsrooms, it is Jeff Bezos’ firm who is blamed for the destruction of retail. The wholesale sacking of the British high street cannot simply be put down to the effects of the economic cycle; instead what we are experiencing is a phase-shift–maybe as great as the shift from serfdom to industrial capitalism a few centuries ago? The challenge is, we have no idea what might lie on the other side of this phase-shift nor how much pain and suffering will be caused while it plays out. Since the dawn of time, philosophers have argued about ethics; and now technologists frequently cite the term also. However, we worry that the definition of ethics is too narrow–particularly in the fields of artificial intelligence where it is limited to technical considerations such as how to mitigate data bias and how to make the workings of algorithms explainable. We see this as an important field, but one where engineering standards, design process, and risk management techniques are the key to mitigating the worst harm. Often also is the conversation about ethics conflated with regulatory compliance. GDPR in Europe has raised the level of consciousness for good data stewardship best practice, and now in California the CCPA achieves similar goals within the U.S. Organisations must of course respond to regulatory change, and seek to influence it also where appropriate—but this is a very different consideration to that of ethics–which we argue is a broader set of questions that speaks to the intention and application of technology, and not merely its implementation. We argue that robust ethics management is an act of negotiation, where dialogue needs to be established with stakeholders who are affected by the technology in question. To be sure, this is a challenge even in small groups, but given the immense reach of modern technology platforms the problem of how to manage ethics appears intractable. And yet it is essential that we get it right if we are to safely guide a path from this side of the phase-shift to the other avoiding the worst consequences along the way. We wonder what lessons can be learned from the last Industrial Revolution if we are to survive the next? In recent years there has been a rise of Environmental, Societal and Governance (ESG) considerations from the Investment Management industry which supports investors who are looking to place capital where it might have the most positive impact, or be free from the gravest potential risks. ESG ratings are now more than just de riguer to investors and consumers, and might in fact be the very nudge necessary to shift focus towards good, long-term best practice and away from short-term financial gain. The challenge ahead of us in proposing similar ESG ratings for Digital Ethics is great. Firstly, we need to ensure the domains of governance are separated–as explained above. Next, we need to ensure a common vernacular. Firms at the leading edge of this debate still use terms such as “ethics boards” and “ethics councils” interchangeably. Finally, we need a framework by which to manage ethics without getting bogged down in the issues of what is right and wrong to us as individuals. If we can agree on such a framework, then we can be hopeful that firms that score highly against the rigour of its implementation will avoid the sort of reputational issues that have mired Facebook, Google, Huawei and others of late. We worry about the future, but we are hopeful also. We are hopeful, particularly because the “techlash” shows us that there are many out there who want to be part of designing our future. What is most striking is how similar our goals are, as whether we are data scientists, politicians, economists, or philosophers–the activity in hand is one of conceiving models for how the world is, how we believe it should be, and designing strategies to nudge us from this place to that. We hope that a focus on ethics can bring people from across these disparate disciplines together, for regardless of our skills and experience–it is a structured conversation about our individual values that we need to hold, and hold at scale. Our values determine the measure by which we live well with ourselves and in accord with others. While we believe ethics are very much a human concern, we believe they now also carry very real commercial benefit.